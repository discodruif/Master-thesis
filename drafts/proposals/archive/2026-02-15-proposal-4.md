# Thesis Proposal: Attention-Based Transformer Models for Joint Option Pricing and Implied Volatility Forecasting

**Author:** Maurits van Eck  
**ANR:** 2062644  
**Program:** MSc Finance  
**Institution:** Tilburg University  
**Date:** February 15, 2026

---

## Part 1: Research Question

Can Transformer architectures that jointly model option pricing and implied volatility surface dynamics outperform specialized models that address these tasks separately, and do the learned attention patterns capture economically meaningful relationships in the options market?

The economic motivation centers on the intrinsic linkage between option prices and implied volatility dynamics. Traditional approaches treat pricing (computing fair value given volatility) and forecasting (predicting future volatility surfaces) as separate problems. However, these tasks share fundamental information: price movements reflect expectations about future volatility, while volatility forecasts depend on current price patterns and market microstructure.

Transformer models, which have revolutionized sequence modeling through self-attention mechanisms, offer a natural framework for capturing these dependencies. This research investigates: (1) Whether joint training on pricing and forecasting tasks improves performance on both compared to task-specific models; (2) Whether attention weights identify economically interpretable patterns (e.g., term structure relationships, moneyness effects); (3) How transformer-based forecasts of the implied volatility surface can generate profitable trading signals after accounting for transaction costs.

This work contributes to the emerging literature on applying modern deep learning architectures to finance and addresses the practical challenge of building integrated systems for pricing and risk forecasting.

---

## Part 2: Literature Review

The relationship between option prices and implied volatility has been studied extensively. Bakshi et al. (2000, *Journal of Finance*) show that implied volatility extracted from options contains information about future realized volatility, establishing the economic linkage between current prices and future dynamics. Christoffersen et al. (2013, *Review of Financial Studies*) demonstrate that implied volatility surfaces have predictable dynamics, motivating forecasting models.

Traditional approaches to volatility surface forecasting use parametric time-series models or factor decompositions (Fengler et al., 2007, *Journal of Financial Economics*). More recently, neural network approaches have shown promise. Medvedev & Wang (2022, *Journal of Futures Markets*) develop deep learning models for multi-step implied volatility surface forecasting, demonstrating superior accuracy compared to GARCH-type benchmarks.

Transformer architectures, introduced by Vaswani et al. (2017, *NeurIPS*), use self-attention mechanisms to capture long-range dependencies in sequences. Applications to financial time series have grown rapidly. Sun et al. (2023, *arXiv*) apply attention-based neural networks to financial market prediction and show improved performance over LSTM baselines. The 2025 paper applying the Informer architecture to option pricing (*arXiv*) demonstrates that Transformers can capture temporal dependencies relevant for derivative valuation.

Multi-task learning, where a single model is trained on related objectives, can improve generalization (Caruana, 1997, *Machine Learning*). Zhang & Yang (2017, *AAAI*) show that shared representations across tasks can improve individual task performance when tasks are sufficiently related. Kelly et al. (2023, *SSRN*) apply this principle to learning from implied volatility surfaces, showing that deep learning can extract predictive structure for returns and risks.

Despite these advances, no prior work has jointly modeled option pricing and volatility surface forecasting within a unified Transformer architecture, nor have attention patterns been analyzed for economic interpretability in this context. This research addresses both gaps.

---

## Part 3: Research Plan

The research design comprises model architecture development, joint training methodology, and economic evaluation.

**Transformer Architecture for Options**

The model takes as input a sequence of historical volatility surface snapshots and option contract features, producing two outputs: current fair prices and forecasted future volatility surfaces.

Input representation for day $t$:
$$
\mathbf{x}_t = \left[\text{SurfaceEmbed}(\sigma_{t-H:t}), \text{ContractEmbed}(K, T), \text{MarketEmbed}(S_t, r_t, \text{VIX}_t)\right]
$$

where $H$ is the lookback window, $\sigma_{t-H:t}$ represents the historical implied volatility surfaces, and embedding layers project contract and market features into a common latent space.

The Transformer encoder processes this sequence using multi-head self-attention:
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

where $Q$, $K$, $V$ are query, key, and value matrices derived from the input embeddings. Multiple attention heads capture different types of relationships (e.g., term structure, cross-strike dependencies).

**Joint Learning Objective**

The model is trained with a combined loss function:
$$
\mathcal{L}_{\text{total}} = \lambda_1 \mathcal{L}_{\text{pricing}} + \lambda_2 \mathcal{L}_{\text{forecast}} + \lambda_3 \mathcal{L}_{\text{regularization}}
$$

where:
- $\mathcal{L}_{\text{pricing}} = \frac{1}{N}\sum_{i=1}^N \left(P_i^{\text{market}} - P_i^{\text{pred}}\right)^2$ measures pricing error
- $\mathcal{L}_{\text{forecast}} = \frac{1}{M}\sum_{j=1}^M \left(\sigma_{j,t+1}^{\text{market}} - \sigma_{j,t+1}^{\text{pred}}\right)^2$ measures next-day volatility surface prediction error
- $\mathcal{L}_{\text{regularization}}$ includes attention entropy penalties to encourage sparse, interpretable attention patterns

**Empirical Evaluation Framework**

Performance is evaluated through three lenses:

**(1) Pricing Accuracy Regression:**
$$
\text{Pricing Error}_{i,t} = \alpha_0 + \alpha_1 \text{Transformer}_{i,t} + \alpha_2 \text{Moneyness}_{i,t} + \alpha_3 \text{Maturity}_{i,t} + \alpha_4 \text{Vol}_{t} + \varepsilon_{i,t}
$$

I hypothesize $\alpha_1 < 0$, indicating lower errors with the joint model compared to baselines (Black-Scholes, neural network pricing-only models).

**(2) Forecasting Accuracy Regression:**
$$
\text{Forecast Error}_{t+1} = \beta_0 + \beta_1 \text{JointModel}_{t} + \beta_2 \text{ForecastOnly}_{t} + \beta_3 \Delta\text{VIX}_{t,t+1} + \eta_{t+1}
$$

where $\text{JointModel}_t$ and $\text{ForecastOnly}_t$ are indicator variables for model type. The coefficient $\beta_1$ tests whether joint training improves forecasting accuracy.

**(3) Trading Strategy Evaluation:**

Using volatility surface forecasts, I construct a volatility arbitrage strategy:
$$
\text{Signal}_{i,t} = \sigma_{i,t+1}^{\text{forecast}} - \sigma_{i,t}^{\text{market}}
$$

If $\text{Signal}_{i,t} > \tau$ (threshold), buy underpriced options; if $< -\tau$, sell overpriced options. Strategy performance is evaluated via:
$$
\text{Sharpe Ratio}_{\text{strategy}} = \frac{\mathbb{E}[R_{\text{strategy}} - R_f]}{\text{SD}(R_{\text{strategy}})}
$$

after accounting for realistic transaction costs (bid-ask spread, slippage).

**Attention Pattern Analysis**

To assess economic interpretability, I analyze learned attention weights across different market conditions. Specifically, I test whether attention patterns correspond to known structural relationships:
- Higher attention to near-the-money strikes (higher information content)
- Term structure dependence (longer-dated options attending to near-term volatility dynamics)
- Regime-dependent attention (different patterns in high vs. low volatility periods)

---

## Part 4: Data Sources

The primary dataset is **OptionMetrics IvyDB US** accessed via WRDS (Wharton Research Data Services), for which Tilburg University provides verified institutional access.

Sample construction:
- **Training**: S&P 500 index options (SPX), 2019-2022 (~1,000 trading days)
- **Validation**: 2023 (~250 days)
- **Testing**: 2024 (~250 days)

Each daily snapshot includes the complete volatility surface (typically 2,000-5,000 liquid contracts spanning strikes from 0.8 to 1.2 moneyness and maturities from 1 week to 1 year).

The dataset provides:
- Option prices (bid, ask, mid)
- Implied volatilities computed using standardized methods
- Contract specifications (strike, maturity, type)
- Underlying index level and returns
- Risk-free rates from the zero-coupon curve
- Greeks (delta, gamma, vega, theta)

**Descriptive Statistics** (projected sample, SPX options 2019-2024):

| Variable | Mean | Std Dev | Min | Max | Observations |
|----------|------|---------|-----|-----|--------------|
| Implied Volatility (%) | 18.45 | 8.72 | 5.30 | 95.40 | ~2,500,000 |
| Moneyness (S/K) | 1.02 | 0.08 | 0.75 | 1.30 | ~2,500,000 |
| Days to Maturity | 45 | 35 | 1 | 365 | ~2,500,000 |
| Option Price ($) | 45.32 | 78.91 | 0.05 | 850.20 | ~2,500,000 |
| Next-Day IV Change (%) | 0.12 | 1.85 | -15.2 | 18.7 | ~2,500,000 |
| VIX Level (%) | 19.85 | 9.12 | 9.14 | 82.69 | ~1,500 days |

Supplementary data:
- VIX index (CBOE) for market volatility regime classification
- SPX returns and realized volatility computed from high-frequency data
- Federal funds rate and term spread (FRED) as macroeconomic controls

---

## Part 5: References

Bakshi, G., Cao, C., & Chen, Z. (2000). Pricing and hedging long-term options. *Journal of Econometrics*, 94(1-2), 277–318.

Caruana, R. (1997). Multitask learning. *Machine Learning*, 28(1), 41–75.

Christoffersen, P., Heston, S., & Jacobs, K. (2013). Capturing option anomalies with a variance-dependent pricing kernel. *Review of Financial Studies*, 26(8), 1963–2006.

Fengler, M. R., Härdle, W. K., & Mammen, E. (2007). A semiparametric factor model for implied volatility surface dynamics. *Journal of Financial Economics*, 86(1), 98–123.

Kelly, B., Kuznetsov, B., Malamud, S., et al. (2023). Deep learning from implied volatility surfaces. SSRN Working Paper. Retrieved from https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4531181

Medvedev, N., & Wang, Z. (2022). Multistep forecast of the implied volatility surface using deep learning. *Journal of Futures Markets*, 42(4), 539–565.

Sun, S., Wang, R., & An, B. (2023). Attention-based neural networks for financial market prediction. *arXiv preprint arXiv:2304.07351*.

Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). Attention is all you need. *Advances in Neural Information Processing Systems*, 30, 5998–6008.

Zhang, Y., & Yang, Q. (2017). A survey on multi-task learning. *IEEE Transactions on Knowledge and Data Engineering*, 34(12), 5586–5609.

arXiv (2025). Applying Informer for option pricing: A transformer-based approach. *arXiv preprint arXiv:2506.05565*.
