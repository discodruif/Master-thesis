# Thesis Proposal: Deep Reinforcement Learning for Multi-Asset Option Hedging with Transaction Costs

**Author:** Maurits van Eck  
**ANR:** 2062644  
**Program:** MSc Finance  
**Institution:** Tilburg University  
**Date:** February 15, 2026

---

## Part 1: Research Question

Can deep reinforcement learning agents learn superior multi-greek hedging strategies for option portfolios that explicitly account for transaction costs, and do these strategies outperform conventional delta-gamma hedging in realistic trading environments?

The economic motivation stems from the fundamental challenge of derivative risk management: classical hedging approaches (e.g., Black-Scholes delta hedging) assume frictionless markets and continuous rebalancing, assumptions that fail dramatically in practice. Transaction costs, discrete rebalancing, and the need to manage multiple risk exposures (delta, gamma, vega) simultaneously create a complex sequential decision problem ideal for reinforcement learning.

This research investigates whether RL agents can discover hedging policies that optimize the trade-off between risk reduction and transaction costs in ways that analytically-derived strategies cannot. Specifically: (1) Can RL agents trained on historical option and underlying data learn hedging policies that minimize P&L variance net of transaction costs? (2) Do RL-based strategies demonstrate superior tail-risk management compared to delta-gamma-vega hedging? (3) How robust are learned policies across different volatility regimes and market conditions?

The practical importance is substantial: improved hedging strategies directly translate to lower capital requirements, reduced risk exposures, and enhanced profitability for options market makers and proprietary trading desks.

---

## Part 2: Literature Review

The challenge of hedging derivatives under market frictions has been studied extensively. Hull & White (1987, *Journal of Finance*) show that transaction costs fundamentally change optimal hedging behavior, leading to sparse rebalancing strategies. Whalley & Wilmott (1997, *Mathematical Finance*) derive asymptotically optimal hedging policies under proportional transaction costs, demonstrating that optimal strategies differ markedly from continuous delta hedging.

Deep reinforcement learning has emerged as a powerful tool for learning optimal policies in complex sequential decision environments (Mnih et al., 2015, *Nature*). The application to derivative hedging was pioneered by Buehler et al. (2019, *Quantitative Finance*), who frame hedging as an RL problem and demonstrate that neural networks can learn effective hedging policies without assuming a specific pricing model.

Recent empirical work has strengthened this foundation. Cao et al. (2021, *arXiv*, 162 citations) apply deep RL to derivatives hedging and show superior performance compared to delta hedging when transaction costs are present. Lucius et al. (2025, *arXiv*) provide a practical framework for option risk management using RL, emphasizing the importance of risk-adjusted metrics and realistic backtesting environments. Pan (2025, *Semantic Scholar*) extends RL hedging using quantile regression and curriculum learning, demonstrating improved tail-risk management.

Multi-greek hedging presents additional complexity. While delta hedging manages first-order price risk, gamma and vega exposures remain. Mandelli et al. (2023, *Semantic Scholar*) apply RL to credit index option hedging, showing that learned policies can manage multiple risk dimensions simultaneously. Vittori et al. (2020, *Semantic Scholar*, 28 citations) demonstrate risk-averse RL formulations for option hedging that explicitly optimize CVaR objectives.

Despite these advances, the literature lacks comprehensive empirical evaluations of RL hedging strategies on multi-asset equity option portfolios with realistic transaction cost structures and market microstructure effects. This research addresses this gap by constructing a high-fidelity trading environment and evaluating RL agents against practitioner benchmarks.

---

## Part 3: Research Plan

The research design comprises four components: environment construction, agent development, training methodology, and empirical evaluation.

**Environment Design**

I construct a Markov Decision Process (MDP) for option portfolio hedging:
- **State**: $s_t = (S_t, \sigma_t^{\text{IV}}, \Delta_{\text{port}}, \Gamma_{\text{port}}, \text{Vega}_{\text{port}}, h_t, t)$ where $S_t$ is the underlying price, $\sigma_t^{\text{IV}}$ is the implied volatility term structure, Greeks capture portfolio exposures, $h_t$ is current hedge position, and $t$ is time.
- **Action**: $a_t \in \mathbb{R}$ represents the hedge trade size in underlying shares.
- **Reward**: $r_t = -(\text{P\&L}_t^2 + \lambda \cdot \text{TC}_t)$ penalizes both hedging variance and transaction costs.

The transition dynamics are learned from historical data rather than assumed, allowing the agent to discover empirical regularities.

**Agent Architecture**

I implement a Proximal Policy Optimization (PPO) agent with the following policy network:

$$
\pi_\theta(a_t | s_t) = \mathcal{N}\left(\mu_\theta(s_t), \sigma_\theta(s_t)^2\right)
$$

where the mean $\mu_\theta$ and variance $\sigma_\theta$ are parameterized by a three-layer feed-forward neural network with 256 hidden units per layer. The value function $V_\phi(s_t)$ uses a similar architecture.

**Training Procedure**

The training objective maximizes expected cumulative reward:

$$
J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta}\left[\sum_{t=0}^T \gamma^t r_t\right]
$$

subject to a KL-divergence constraint to ensure stable updates. I use a mini-batch size of 1024 experiences and update the policy every 10,000 timesteps.

**Empirical Evaluation**

Performance is evaluated using a rolling-window out-of-sample backtest on S&P 100 equity options (2019-2024). The primary evaluation regression is:

$$
\text{Hedging Cost}_{i,t} = \beta_0 + \beta_1 \text{RL}_{i,t} + \beta_2 \text{DeltaOnly}_{i,t} + \beta_3 \text{Vol}_{t} + \beta_4 \text{PortSize}_{i,t} + \varepsilon_{i,t}
$$

where $\text{RL}_{i,t}$ and $\text{DeltaOnly}_{i,t}$ are strategy indicators. Hedging cost is measured as the standard deviation of daily P&L net of transaction costs. I hypothesize $\beta_1 < 0$, indicating lower hedging costs with RL strategies.

To assess tail risk, I estimate quantile regressions at the 5th and 95th percentiles:

$$
Q_{0.05}(\text{P\&L}_{i,t}) = \gamma_0 + \gamma_1 \text{RL}_{i,t} + \text{Controls}_{i,t} + \nu_{i,t}
$$

A successful RL strategy should reduce both variance and extreme losses while maintaining reasonable transaction costs.

---

## Part 4: Data Sources

The primary dataset is **OptionMetrics IvyDB US** accessed via WRDS (Wharton Research Data Services). Tilburg University provides institutional access, which I have verified through the library portal.

The sample focuses on **S&P 100 constituent equity options** from January 2019 to December 2024. This subset provides:
- Sufficient liquidity for realistic transaction cost modeling
- Diverse underlying characteristics (sectors, volatilities, correlations)
- Coverage of multiple volatility regimes (2020 COVID, 2022 inflation shock)

The dataset includes:
- Option prices (bid, ask, mid) at daily frequency
- Implied volatilities across the strike-maturity surface
- Greeks (delta, gamma, vega, theta, rho) computed using the volatility surface
- Underlying stock prices and returns
- Trading volumes and open interest for transaction cost estimation

**Transaction Cost Model**: Proportional costs are estimated from bid-ask spreads. For the underlying equity, I use $\text{TC} = 0.05\%$ (5 basis points). For options, costs vary by moneyness and liquidity, ranging from 0.1% to 1% of notional value.

**Descriptive Statistics** (projected sample, S&P 100 options 2019-2024):

| Variable | Mean | Std Dev | Min | Max | Observations |
|----------|------|---------|-----|-----|--------------|
| Option Price ($) | 12.45 | 18.32 | 0.10 | 320.50 | ~8,000,000 |
| Portfolio Delta | 0.02 | 8.45 | -50.0 | 50.0 | ~50,000 |
| Portfolio Gamma | 1.85 | 3.20 | -15.0 | 20.0 | ~50,000 |
| Portfolio Vega | 125.3 | 220.5 | -800 | 1200 | ~50,000 |
| Daily P&L Volatility ($) | 4,250 | 5,100 | 100 | 85,000 | ~50,000 |
| Hedge Trade Size (shares) | 850 | 1,200 | -10,000 | 12,000 | ~50,000 |
| Transaction Costs ($) | 125 | 180 | 5 | 2,500 | ~50,000 |

Supplementary data (VIX, market returns, sector indices) from FRED and Yahoo Finance will be merged for contextual features.

---

## Part 5: References

Buehler, H., Gonon, L., Teichmann, J., & Wood, B. (2019). Deep hedging. *Quantitative Finance*, 19(8), 1271–1291.

Cao, J., Chen, J., Hull, J., & Poulos, Z. (2021). Deep hedging of derivatives using reinforcement learning. *arXiv preprint arXiv:2103.16409*.

Hull, J. C., & White, A. (1987). Hedging the risks from writing foreign currency options. *Journal of International Money and Finance*, 6(2), 131–152.

Lucius, T., Koch, C., Starling, J., Zhu, J., Urena, M., & Hu, C. (2025). Deep hedging with reinforcement learning: A practical framework for option risk management. *arXiv preprint arXiv:2512.12420*.

Mandelli, F. (2023). Reinforcement learning for credit index option hedging. Semantic Scholar, Retrieved from https://www.semanticscholar.org/paper/b54ae0dea9033964af33ec8e1f2d3875b9af3348

Mnih, V., Kavukcuoglu, K., Silver, D., et al. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529–533.

Pan, Q. (2025). Reinforcement learning for option hedging using quantile regression and curriculum learning with historical data fusion. Semantic Scholar, Retrieved from https://www.semanticscholar.org/paper/93fea217fb8c7a13fb96b5e20701c7dbceaaf1a5

Vittori, E. (2020). Option hedging with risk averse reinforcement learning. Semantic Scholar, Retrieved from https://www.semanticscholar.org/paper/f7a69a1bcc0b00f5ddd05be02934390332aa7a64

Whalley, A. E., & Wilmott, P. (1997). An asymptotic analysis of an optimal hedging model for option pricing with transaction costs. *Mathematical Finance*, 7(3), 307–324.
